We implement all the graph mining algorithms using Postgres's embedded PL/pgSQL programming language, which supports many advanced features, like user defined function, aggregate, etc. It also has a sophisticated query execution engine, which we think is the most critical component of Postgres.

The following are the algorithms we plan to implement. The reason we choose them is that there are a lot of implementation in other platform like MapReduce, we can compare our SQL version with them to draw a clusion about SQL's unique charastic in solving data analytic tasks.

\begin{description}
  \item[Degree Distribution:] Plot the distribution of each node's degree. 
  \item[PageRank:] Determine the importance of every node of a graph based on its connectivity. 
  \item[Connected Components:] Partition the nodes of a graph also based on its connectivity.
  \item[Radius of Every Node:] Compute the radius of every node in a graph. The radius is defined as the number of hops that a node needs to reach to its furthest neighbor.
  \item[Belief Propagation:] Calculate the marginal probability of each node in a graphical model. 
  \item[Eigenvalue:] Using approximation method to estimate the top-k eigenvalues of a matrix.
  \item[Count of triangle] Using approcimate method to calculate the number of triangles in a social network.
  \item[Shortest Path] Calculate the shortest path from each node in a graph to a single source node. 
  \item[Minimum spanning tree] Construct a tree which is a subgraph of original graph with the minimum sum of weight of its edges. 
\end{description}

\subsection{Degree Distribution}
We employ Postgres's group by command according to either source node or target node to count the degree distribution according to each node. The psueudo code is in Algorithm \ref{algo1:1}, \ref{algo1:2}.

\begin{algorithm}
\caption{Out Degree distribution}
\begin{algorithmic}
\STATE{Group edges according to source node's id}
\STATE{Count the number of members of each group}
\end{algorithmic}
\label{algo1:1}
\end{algorithm}

\begin{algorithm}
\caption{In Degree distribution}
\begin{algorithmic}
\STATE{Group edges according to target node's id}
\STATE{Count the number of members of each group}
\end{algorithmic}
\label{algo1:2}
\end{algorithm}

\subsubsection{Math}
First we need to count degree of each node. Then we count the frequency of each degree count. 

\subsubsection{Idea of SQL implementation}
The only operation we need from SQL is its group by clause. We can aggregate the edges according with source node or target node.

\subsubsection{SQL code}
Please refer to the code in {\bf Appendix}.

\subsection{Pagerank}
The algorithm of pagerank is Power method. We do matrix multiplication continuously until the change in pagerank is small. The most important euqation for calculating pagerank is as follows:
\begin{equation}
  PR(i) = \alpha \frac{1}{N} + (1 - \alpha) \sum_{j \in InNeighbor(i)} \frac{PR(j)}{OutDegree(j)}
\end{equation}
\begin{algorithm}
\caption{Pagerank}
\begin{algorithmic}
\STATE{Bulk load graph into an edge table in database.}
\STATE{Initialization(damper factor=0.85, max iteration = 100, epsilon = 0.0001)}
\STATE{Build a weight matrix trans, initialize pagerank p}
\REPEAT
\STATE{For each node i, update its pagerank with its old value and its income node's pagerank.}
\UNTIL{Convergence}
\end{algorithmic}
\end{algorithm}

\subsubsection{Math}
According to the definition of pagerank, we can gain an intuitive idea of how to calculate the pagerank of a node.
We just take weighted sum of its incoming neighbors. We can encode this operation as matrix vector multiplication.
We can do this multiple times. And the fix point of the equation is the pagerank of the graph. And by the results 
from linear algebra, we know that the stable vector is the eigenvector with biggest eigenvalue. Thus we can get 
the eigenvector by power method, which just do multiplication until convergence. 

\subsubsection{Idea of SQL implementation}
The implementation consists of several components.
First, we have a \emph{graph} which has the schema \emph{(from\_id, to\_id, weight)}. Then we will build a \emph{rank} table has the schema \emph{(node\_id, rank)}, all the rank are initialized randomly. After we enter loop, we will do a large matrix vector multiplication, which is implemented by SQL \emph{select} and \emph{join}. The new pagerank is stored in a temporary table. After the loop is over, we calclate the updates to every node, if the change is little, then abort.

\subsubsection{SQL code}
Please refer to the code in {\bf Apppendix}.

\subsection{Weakly connected components}
In terms of the implementation of weakly connected components. We borrow the idea of HCC method from the "PEGASUS" paper.\cite{Kang09}

\subsubsection{Idea of SQL implementation}
The algorithm can be described in algorithm \ref{algo:wcc}. The key step that updates the 
component id to the minimum of its neghbors' is accomplished in SQL using join and group by
clause.
\begin{algorithm}
\caption{Weakly Connected Component}
\begin{algorithmic}
\STATE{Bulk load graph into an edge table in database.}
\STATE{Create a component table, where each entry contains a node id, and the component id.}
\STATE{Initialize the component table where component id equls node id.}
\REPEAT
\STATE{For each node, assign the minimum component id of its neighbors as the new componnet id of this node.}
\UNTIL{Convergence}
\end{algorithmic}
\label{algo:wcc}
\end{algorithm}
After several rounds of iteration, the nodes in the same connected component will share the same component id.
The number of iterations for convergence can be proved to be upper bounded by the diameter of the graph.

\subsubsection{SQL code}
Please refer to the code in {\bf Apppendix}.

\subsection{Radius of every node}
We discard the traditional algorithm because it is extremely infeasible for large graphs, since it uses a set to record every neghbors within n hops for a node during iteration, which requires a O($n^2$) space.
Since the exact algorithm is hopeless, we use the approximation algorithm described in "HADI" paper\cite{DBLP:journals/tkdd/KangTAFL11} instead. Specifically, we use the Flajolet-Martin algorithm for counting the number of distinct members in a multiset. It is guaranteed to give an unbiased estimate and a tight O($log(N)$) bound for space complexity. The basic idea of Floajolet-Martin algorthm is to use a bitstrings of length $L$ to encode the set. For each element to add, we randomly pick up a index according to a specified distribution, and assign BITMAP[index] to 1. Following this procedure to add element, the size of the final set can be estimated by $\frac{1}{\phi} 2^{\frac{1}{k}\sum_{i=1}^k R_i}$, where $\phi$ = 0.77351, $R_i$ denotes the index of the leftmost 0 in the the $k$th bitstring.

In our proposed method for computing radius of every node, we use the Flajolet-Martin(FM) bitstrings to encode the neighbors of every node. Formally, we use $k$ FM-bitstrings $b(h, i)$ to represent the set of neighbor nodes reachable from $node_i$ within h hops. And for each iteration, we use the following way to update each FM-bitstring:$$b(h,i) = b(h-1,i)  \quad BIT-OR \quad  {b(h-1,j)|(i,j)\in E}$$

Given the above description of how to encode neighbors of a node, and the method to update bitstrings, we can describe the approximation method we used to compute the raidus of every node in algorithm \ref{radius:algo3}.

\begin{algorithm}
\caption{Radius of Every Node}
\begin{algorithmic}
\STATE{Bulk load graph into an edge table in database.}
\STATE{Preprocess the edge table, add a self loop edge to every node in the graph.}
\STATE{Initialize the vertex table, which contains node id, and a column of bitstring array, the bitstrings are initialized using the FM algorithm}
\REPEAT
\STATE{For every node update the bitstring according to formula: $b(h,i) = b(h-1,i) \quad BIT-OR \quad  {b(h-1,j)|(i,j)\in E}$. }
\STATE{For every node, check whether the bitstrings is unchanged before and after updates, if it's not changed, output i as the radius for this node.}
\UNTIL{The bitstrings of every node stabilizes or it reaches the maximum rounds of iteration.}
\end{algorithmic}
\label{radius:algo3}
\end{algorithm}

\subsubsection{Idea of SQL implementation}
In our implementation of this algorithm in SQL, we defined some user defined functions in PostgreSQL. The key step of algorithm that updates the FM-bitstring array is accomplished by using aggBitOr in the join and group by clause. Specifically, we join the edge table and vertex table on dst id, group by src id, and then call the aggBitOr to update the fm string array for all nodes.
\begin{description}
  \item[fmAssign:] Assign the k FM-bitstrings for a node.
  \item[bitOr:] Execute the OR operations between two bitstring arrays.
  \item[aggBitOr:] Aggregate function for bitOr.
  \item[fmSize:] Estimate the size of a set encoded by FM-bitstring.
\end{description}

\subsubsection{SQL code}
Please refer to the code in {\bf Apppendix}.


\subsection{Belief Propagation}
For belief propagation, we use the fabp method proposed in paper\cite{DBLP:conf/pkdd/KoutraKKCPF11}.
It can be shown that the solution of belief propagation can be approximated by the linear system:$$[\mathbf{I}	 + a\mathbf{D} - c\mathbf{A}]\mathbf{b_h} = \mathbf{\phi_h}$$ 
where $\mathbf{A}$ is the n by n symmetric adjacency matrix, $\mathbf{D}$ is the diagonal matrix of degrees, $b_h$ corresponds to the vector of final beliefs for each node, $\phi_h$ is prior belief vector, and $h_h$ is the homophily factor,  $a = 4h_h^2/(1 - h_h^2)$ and $c = 2h_h / (1-4h_h^2)$.

To solve this linear system, we can see :$\mathbf{I} + a\mathbf{D} - c\mathbf{A}$ as the form $\mathbf{I} - \mathbf{W}$, where $\mathbf{W} = -a\mathbf{D} + c\mathbf{A}$, and using the expansion:$$(\mathbf{I} - \mathbf{W})^{-1} = \mathbf{I} + \mathbf{W} + \mathbf{W}^2 + \mathbf{W}^3 + ...$$

and the solution of the linear system is given by the formula:
$$\mathbf{b_h} = (\mathbf{I} - \mathbf{W}^{-1})\mathbf{\phi_h} =\mathbf{\phi_h}  + \mathbf{\phi_h} \mathbf{W} + \mathbf{\phi_h} \mathbf{W}^2 + \mathbf{\phi_h} \mathbf{W}^3 + ...$$

Given this power method, the implementation is pretty straightforward as described in algorithm \ref{bp:algo4}.
\begin{algorithm}
\caption{Belief Propagation}
\begin{algorithmic}
\STATE{Bulk load graph into an edge table in database.}
\STATE{Initialize $h_h = 0.001 $}
\STATE{Initialize the initial belief of every node as prior belief}
\REPEAT
\STATE{Update the belief of node by $b_h(i) = b_h(i-1)\mathbf{W} + \mathbf{\phi_h}$ }
\UNTIL{Convergence}
\end{algorithmic}
\label{bp:algo4}
\end{algorithm}

\subsubsection{Idea of SQL Implementation}
The major computation involved is matrix vector multiplication, which is easy to implement in SQL using join and group by step.

\subsubsection{SQL code}
Please refer to the code in {\bf Appendix}.

\subsection{Eigenvalue}
We adopt the method propose in \cite{kang2011spectral}. There are several methods to solve part of eigenvalue computation problems, for instance, power method\cite{langville2004deeper}. While it has the limitation that it can only extract the eigenvector with biggest eigenvalue. Several method have been proposed to extract top k eigenvectors simultaneously. The approach we use is Lanczos algorithm\cite{lanczos1950iteration}. The general idea about this algorithm is that instead of directly work on an $N \times N$ matrix, we first generate a skinny $N \times m$ matrix(M $\ll$ N). Then it computes a small $M \times M$ dense matrix which has good approximation to the eigenvalues of the original matrix. In this case, we directly apply quadratic algorithm to top-k eigenvalues. Notice that k $<$ M.

\begin{algorithm}
{\bf Input:} Matrix $A^{n \times m}$\\
random n-vector $b$,\\
number of steps m\\
{\bf output:} Orthogonal matrix $ V^{v \times m}_{m} = [v_{1}\cdots v{m}]$,\\
coefficients $\alpha[1..m]$ and $\beta[1..m-1]$
\begin{algorithmic}[1]
\caption{Lanczos algorithm}
\STATE $\beta_{0} \leftarrow 0, v_{0} \leftarrow 0, v_{1} \leftarrow \frac{b}{\parallel b \parallel}$ 
\FOR {$i=1$ to $m$}
	\STATE $v \leftarrow Av_{i}$
	\STATE $\alpha_{i} \leftarrow v^{T}_{i}v $
	\STATE $v \leftarrow v - \beta_{i-1}v_{i-1} - \alpha_{i}v_{i}$
	\STATE $\beta_{i} \leftarrow \parallel v\parallel $
	\IF {$\beta_{i} = 0$} 
	\STATE break for loop 
	\ENDIF
	\STATE $ v_{v+1} \leftarrow \frac{v}{\beta_{i}} $
\ENDFOR
\end{algorithmic}
\label{eigen:algo1}
\end{algorithm}

\begin{algorithm}
\caption{Build tridiagonal matrix}
{\bf Input:} $\alpha, \beta$
{\bf Output:} $T^{m\times m}_{m}$
\begin{algorithmic}[1]
\FOR {$i=1$ to m}
	\STATE $T[i, i] \leftarrow \alpha_{i} $
	\STATE $T[i, i+1] = T[i+1, i] \leftarrow \beta_{i}$
\ENDFOR	
\end{algorithmic}
\label{eigen:algo2}
\end{algorithm}

\begin{algorithm}
\caption{Compute Ritz values}
{\bf Input:}Orthogonal matrix $V^{n\times m}_{m}$\\
coefficients $\alpha[1..m]$ and $\beta[1..m-1]$
\begin{algorithmic}[1]
\STATE $T_{m} \leftarrow$ (build a tridiagonal matrix from $\alpha$ and $\beta$)
\STATE $QDQ^{T} \leftarrow EIG(T_{m})$
\STATE $\lambda_{1..k} \leftarrow$ (top k eigenvalues from D)
\STATE $Q_{k} \leftarrow $ (k columns of Q corresponding to $\lambda_{1..k})$
\STATE $R_{k} \leftarrow V_{m}Q_{k}$
\end{algorithmic}
\label{eigen:algo3}
\end{algorithm}

\subsubsection{Math}
Different from power method, the intermediate multiplication matrix is used to construct a set of orthonormal base of \emph{Krylv subspace $K_{m}$} which follows the definition:
\begin{equation}
K_{m} = < b, Ab, \cdots, A^{m-1}b>.
\end{equation}
The sub procedure to construct orthonormal bases may be any standard algorithm, for example Gram-schmidt algorithm. We can view Lanczos algorithm as an iterative method which incrementally construct Krylov subspace. The pseudo-code is shown in Algorithm \ref{eigen:algo1}.

After Lanczos factorization, we get a few matrices that satisfy the following equation:
\begin{equation}
	AV_{m} = V_{m}T_{m} + f_{m}e^{T}_{m}
\end{equation}
To name a few, $A^{n\times m}$ is input matrix, $V^{n\times m}_{m}$ contains the m orthonormal bases, $T^{m\times m}_{m}$ is a tridiagonal matrix, $f_{m}$ is new n-vector orthogonal to all columns of $V_{m}$, $
e_{m}$ is a vector that \emph{m}th element is 1, and others 0. After algorithm \ref{eigen:algo1}, we need to construct the matrix $T^{m\times m}_{m}$. The algorithm is quite simple, it is listed in algorithm \ref{eigen:algo2}. 

The eigenvalues of $T_{m}$ are called Ritz values, and $V_{m}Y$'s columns are called Ritz vector. It is constructed by Algorithm \ref{eigen:algo3}. We expect the Ritz values and Ritz vectors to be good approximation of the eigenvalues and eigenvectors of original matrix. The computation of eigenvalues of $T_{m}$ can be done by standard quadratic algorithms, such as QR method. 


\subsubsection{Idea of SQL implementation}
Since the algorithm of Lanczos algorithm is matrix calculation intensive, so we wrap all matrix related operation in our host language Python. I'll list the most important routines that appears very often in my high level implementation of Lanczos. Then in the final python code, I'l just call these wrappers instead of using raw SQL again and again.
\begin{description}
  \item[create\_vector\_or\_matrix:]{declare a vector/matrix variable}
  \item[assign\_to:]{Copy a variable's value to another variable}
  \item[vetorr\_length:]{Return the length of a vector}
  \item[vector\_dot\_product:]{take the dot product of two vectors}
  \item[reverse\_matrix:]{Append reverse of every edge into original graph}
  \item[matrix\_multiply\_matrix\_overwrite:]{Multiply a matrix with a matrix}
  \item[matrix\_multiplt\_vector\_overwrite:]{Multiply a matrix with a vector}
  \item[normalzed\_vector:]{Normalize a vector}
\end{description}

\subsubsection{SQL code}
Please refer to the code in {\bf Apppendix}.

\subsection{Count of Triangle}
We use a simple technique proposed by \cite{tsourakakis2008fast}, its general idea is build upon a theorem that the count of triangles in a graph is proportional to the sum of cubes of eigenvalues of the graph. 


\subsubsection{Global triangle}
The algorithm to calculate global triangles is as follows:

\paragraph{Math}
The formula to count global triangle is sum of cubes of eigenvalues, which is:
\begin{equation}
    \Delta(G) \gets \frac{1}{6} \sum_{j=1}^{i-1}\lambda_{j}^{3}
\end{equation}

\begin{algorithm}
\caption{The EigenTriangle algorithm}
{\bf Require: } Adjecency matrix A (n X n)\\
{\bf Require: } Tolerence \emph{tol}\\
{\bf Output: } $\bigtriangleup'(G)$ global triangle estimation
\begin{algorithmic}
\STATE{$\lambda_{i} \leftarrow LanczosMethod(A, 1)$}
\STATE{$\overrightarrow{\Lambda} \gets [\lambda_{1}]$}
\STATE{$i \gets 2 \{ $ {initialize i, $\overrightarrow{\Lambda}$} \} }
\REPEAT 
    \STATE{$\lambda_{i} \leftarrow LanczosMethod(A, i)$}
    \STATE{$\overrightarrow{\Lambda} \gets [\overrightarrow{\Lambda} \lambda_{i}]$}
    \STATE{$i \gets i + 1$}
\UNTIL{0 $\leq$ $\frac{|\lambda_{i}^3|}{\sum_{j=1}^{i} |\lambda_{i}|^3} \leq$ tol}
\STATE{$\bigtriangleup'(G) \gets \frac{1}{6} \sum_{j = 1}^{i} \lambda_{i}^3$}
\RETURN{$\bigtriangleup'(G)$}
\end{algorithmic}
\end{algorithm}

\subsubsection{Local triangle}
The algorithm to calculate the local triangle is as follows.

\paragraph{Math}
$\Delta_{i}$ is the number of local triangles that node i participated in. The formula of local triangle count is based on the following theorem:
\begin{equation}
    \Delta_{j} = \frac{\sum_{k=1}^{i-1}u_{jk}^{2}\lambda_{k}^{3}}{2}
\end{equation}


\begin{algorithm}[!htbf]
\caption{The local eigentriangle algorithm\cite{tsourakakis2008fast}}
\begin{algorithmic}
\REQUIRE Adjacency matrix $A(n \times n)$
\REQUIRE Tolerance $tol$\\
{\bf OUTPUT: } $\Delta'(G)$  per node triangle estimation
\STATE $\langle \lambda_{1},\vec{u_{1}} \rangle \leftarrow LanczosMethod(A,1)$
\STATE $\vec{\Lambda} \leftarrow [\lambda_{1}]$
\STATE $\bigcup \leftarrow [\vec{u_{1}}]$
\STATE $i \leftarrow 2$
\REPEAT
\STATE $\langle \lambda_{i},\vec{u_{i}} \rangle \leftarrow LanczosMethod(A,i)$
\STATE $\vec{\Lambda} \leftarrow [\vec{\Lambda}\lambda_{i}]$
\STATE $\bigcup \leftarrow [\bigcup \vec{u_{1}}]$
\STATE $i \leftarrow i + 1$
\UNTIL $0 \leq \frac{|\lambda_{i}^3|}{\Sigma_{j=1}^{i-1}\lambda_{j}^3} \leq tol$
\FOR   {$j=1$ to $n$}
\STATE $\bigtriangleup_{j} = \frac{\Sigma_{k=1}^{i-1}u_{jk}^2\lambda_{k}^3}{2}$
\ENDFOR
\STATE $\bigtriangleup(G)\leftarrow[\bigtriangleup_{1},\ldots,\bigtriangleup_{n}]$
\RETURN $\bigtriangleup(G)$
\end{algorithmic}
\end{algorithm}




\subsubsection{Idea of SQL implementation}
We will call Lanczos to get the eigenvalues and eigenvectors of the graph, and sum up the number using SQL \emph{select}.

\subsubsection{SQL code}
Please refer to the code in {\bf Appendix}.

\subsection{Shortest Path}
We adopt Dijkstra's shortest algorithm to compute shortest path from the source node. It works for directed weighted
graph which has $O(|V| log |V| + |E|)$ time complexity. The psueudo code is listed in algorithm \ref{algo:dijkstra}.

\begin{algorithm}[!htbf]
{\bf Input:} Source node and directed weighted graph. \\
{\bf Output:} Shortest path of every node from source node. 
\begin{algorithmic}
\caption{Dijkstra shortest path algorithm}
\FORALL{node V in graph} 
    \STATE{dist[V] $\gets$ infinity} 
    \STATE{visited[V] $\gets$ false }
\ENDFOR
\STATE{dist[source] $\gets$ 0}
\STATE{insert source into Q}
\WHILE{Q is not empty} 
    \STATE{u $\gets$ vertex in Q with smallest distance} 
    \STATE{remove u from Q}
    \STATE{visited[u] $\gets$ true}
    \FORALL{neighbour v of u}
        \STATE{alt $\gets$ dist[u] + dist\_between(u, v)}
        \IF{alt $<$ dist[v] \&\& !visited[v]} 
            \STATE{dist[v] $\gets$ alt} 
            \STATE{insert v into Q}
        \ENDIF
    \ENDFOR
\ENDWHILE
\end{algorithmic}
\label{algo:dijkstra}
\end{algorithm}

\subsubsection{Idea of SQL implementation}
This is implemented purely in SQL. Just like ordinary C code, I have a table to record the current status(visited, distance) of each node, and update one node at a time. 

\subsubsection{SQL code}
Please refer to the code in {\bf Apppendix}.

\subsection{Minimum Spanning Tree}
We use the classical Prim's algorithm for this additional task. We abandon the Kruskal's algorithm because the disjoint set is not easy to implement using SQL.

\subsubsection{Idea of SQL implementation}
The implementation in SQL can be described in algorithm \ref{algo:prim}.
 
\begin{algorithm}
{\bf Input:} Edge Table E of a undirected connected graph \\
{\bf output:} Edge Table MST containing edges of the minimum spanning tree
\begin{algorithmic}
\caption{Prim's algorithm}
\STATE Create a node table N
\STATE Randomly insert a node into N
\FOR {$i=1$ to $number of nodes - 1$}
	\STATE Insert into MST an edge from E with minimum weight where src node is in N and destination node is not in N
	\STATE Insert into N with the destination node of the edge selected in last step
\ENDFOR
\end{algorithmic}
\label{algo:prim}
\end{algorithm}

\subsubsection{SQL code}
Please refer to the code in {\bf Apppendix}.



